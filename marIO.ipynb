{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rw/micrograd/.venv/lib/python3.11/site-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rw/micrograd/.venv/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# Initialize Super Mario environment (in v0.26 change render mode to 'human' to see results on the screen)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", new_step_api=True)\n",
    "else:\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='rgb', apply_api_compatibility=True)\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "# env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "class JSSPACE(JoypadSpace):\n",
    "    def __init__(self, env, actions):\n",
    "        super(JSSPACE, self).__init__(env, actions)\n",
    "\n",
    "    def reset(self,  *args, **kwargs,):\n",
    "        return self.env.reset()\n",
    "\n",
    "\n",
    "env = JSSPACE(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, SupportsFloat\n",
    "\n",
    "\n",
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        return super().render(*args, **kwargs)\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "    \n",
    "\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = FrameStack(env, num_stack=4, new_step_api=True)\n",
    "else:\n",
    "    env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(*args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Given a state, choose an epsilon-greedy action\"\"\"\n",
    "        pass\n",
    "\n",
    "    def cache(self, experience):\n",
    "        \"\"\"Add the experience to memory\"\"\"\n",
    "        pass\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"Sample experiences from memory\"\"\"\n",
    "        pass\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"Update online action value (Q) function with a batch of experiences\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "        self.net = self.net.to(device=self.device)\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5  # no. of experiences between saving Mario Net\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    Given a state, choose an epsilon-greedy action and update value of step.\n",
    "\n",
    "    Inputs:\n",
    "    state(``LazyFrame``): A single observation of the current state, dimension is (state_dim)\n",
    "    Outputs:\n",
    "    ``action_idx`` (``int``): An integer representing which action Mario will perform\n",
    "    \"\"\"\n",
    "        # EXPLORE\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # EXPLOIT\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # decrease exploration_rate\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # increment step\n",
    "        self.curr_step += 1\n",
    "        return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):  # subclassing for continuity\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\"cpu\")))\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        # self.memory.append((state, next_state, action, reward, done,))\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarioNet(nn.Module):\n",
    "    \"\"\"mini CNN structure\n",
    "  input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim)\n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        # Q_target parameters are frozen.\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "\n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        \n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.burnin = 1e4  # min. experiences before training\n",
    "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4  # no. of experiences between Q_target & Q_online sync\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "\n",
      "Episode 0 - Step 311 - Epsilon 0.9999222530127239 - Mean Reward 1018.0 - Mean Length 311.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 2.71 - Time 2024-05-11T20:08:33\n",
      "Episode 3 - Step 881 - Epsilon 0.9997797742256939 - Mean Reward 810.0 - Mean Length 220.25 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 5.106 - Time 2024-05-11T20:08:39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 4\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset(seed=420)\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        # Remember\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarioNet saved to checkpoints/2024-05-11T20-08-31/mario_net_0.chkpt at step 881\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "mario.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rw/micrograd/.venv/lib/python3.11/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/rw/micrograd/.venv/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m env \u001b[38;5;241m=\u001b[39m GrayScaleObservation(env)\n\u001b[1;32m     12\u001b[0m env \u001b[38;5;241m=\u001b[39m ResizeObservation(env, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m84\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     action \u001b[38;5;241m=\u001b[39m mario\u001b[38;5;241m.\u001b[39mact(state)\n",
      "File \u001b[0;32m/nix/store/2kr0sgrp3xrq0279bfnifdhhhv12d8v6-python3.11-gymnasium-0.29.1/lib/python3.11/site-packages/gymnasium/core.py:515\u001b[0m, in \u001b[0;36mObservationWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`reset`, returning a modified observation using :meth:`self.observation`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(obs), info\n",
      "File \u001b[0;32m/nix/store/2kr0sgrp3xrq0279bfnifdhhhv12d8v6-python3.11-gymnasium-0.29.1/lib/python3.11/site-packages/gymnasium/core.py:515\u001b[0m, in \u001b[0;36mObservationWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`reset`, returning a modified observation using :meth:`self.observation`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mseed, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(obs), info\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# MarioNet saved to checkpoints/2024-05-11T19-35-01/mario_net_0.chkpt at step 3142\n",
    "# use the saved model to play the game\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "mario.net.load_state_dict(torch.load(\"checkpoints/2024-05-11T19-35-01/mario_net_0.chkpt\")[\"model\"])\n",
    "mario.net = mario.net.to(device=\"cpu\")\n",
    "# Play the game!\n",
    "# Apply Wrappers to environment\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
    "env = JSSPACE(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "state = env.reset()\n",
    "while True:\n",
    "    action = mario.act(state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    state = next_state\n",
    "    env.render(render_mode='human')\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
